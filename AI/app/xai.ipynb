{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI (xAI) Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Muscle Group Classification, two models had very high results: SVC and Random Tree Classifier. In order to know the models are not only making the right decisions but also making them for the right reasons, we use xAI models to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # Import helper functions\n",
    "from mediapipe_handler import MediaPipeHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current OS working directory is h:\\DesD_AI_pathway\\AI\\app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mediapipe_model = MediaPipeHandler()\n",
    "\n",
    "#training_dataset=mediapipe_model.read_csv_to_pd(\"/Users/yasinetawfeek/Developer/DesD_AI_pathway/AI/data/train_new.csv\")\n",
    "#testing_dataset=mediapipe_model.read_csv_to_pd(\"/Users/yasinetawfeek/Developer/DesD_AI_pathway/AI/data/test_new.csv\")\n",
    "\n",
    "training_dataset=mediapipe_model.read_csv_to_pd(r\"H:\\\\DesD_AI_pathway\\\\AI\\\\data\\\\train_new.csv\")\n",
    "testing_dataset=mediapipe_model.read_csv_to_pd(r\"H:\\\\DesD_AI_pathway\\\\AI\\\\data\\\\test_new.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Removes original feature and splits it into x,y,z components\n",
    "\n",
    "\"\"\"\n",
    "def Preprocess_data(dataframe,columns_to_flatten):\n",
    "    final_df=dataframe.copy()\n",
    "    # Expanding each column into 3 separate columns (x, y, z) and appending it to the final dataframe.\n",
    "    for column in columns_to_flatten:\n",
    "        # print(np.vstack(dataframe[column]).astype(float))\n",
    "        expanded_df=pd.DataFrame(np.vstack(dataframe[column]).astype(float), \n",
    "                           columns=[column+'_x', column+'_y', column+'_z'],\n",
    "                           index=dataframe.index)\n",
    "        new_df = pd.concat([dataframe.drop(column, axis=1), expanded_df], axis=1)\n",
    "        for new_column in new_df.columns:\n",
    "            final_df[new_column] = new_df[new_column]\n",
    "\n",
    "    return final_df.drop(columns=columns_to_flatten,axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Splits dataset into X_train,y_train or X_test,y_test, if you give it training dataset then X_train and y_train\n",
    "\n",
    "\"\"\"\n",
    "def Return_X_y(dataframe,columns_to_delete):\n",
    "    X=dataframe.drop(columns=columns_to_delete)\n",
    "    y=dataframe['muscle group']\n",
    "    return X,y\n",
    "\n",
    "features_to_split=['left_shoulder',\n",
    "       'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist',\n",
    "       'right_wrist', 'left_hip', 'right_hip', 'left_knee',\n",
    "       'right_knee', 'left_ankle', 'right_ankle']\n",
    "\n",
    "training_dataset_preprocessed=Preprocess_data(training_dataset,features_to_split)\n",
    "X_train, y_train = Return_X_y(training_dataset_preprocessed,['label','muscle group','image','Unnamed: 0'])\n",
    "\n",
    "\n",
    "testing_dataset_preprocessed=Preprocess_data(testing_dataset,features_to_split)\n",
    "X_test, y_test = Return_X_y(testing_dataset_preprocessed,['label','muscle group','image','Unnamed: 0'])\n",
    "\n",
    "columns_to_drop = ['left_heel_z', 'left_elbow_z', 'right_shoulder_y', 'right_elbow_x', 'right_pinky_z', 'left_ankle_x', 'right_hip_z', 'right_ankle_z', 'right_wrist_z', 'right_pinky_y', 'left_pinky_x', 'left_wrist_x', 'left_foot_index_z', 'right_foot_index_y', 'left_wrist_z', 'right_thumb_x', 'left_index_y', 'left_foot_index_y', 'right_hip_y', 'right_index_z', 'right_foot_index_x', 'left_knee_y', 'right_knee_y', 'right_knee_x', 'left_foot_index_x', 'left_thumb_x', 'right_foot_index_z', 'left_thumb_z', 'right_elbow_z', 'left_heel_x', 'left_ankle_y', 'left_pinky_y', 'left_pinky_z', 'right_thumb_y', 'right_heel_z', 'right_ankle_x', 'right_heel_y', 'right_index_y', 'left_ankle_z', 'left_elbow_x', 'right_index_x', 'right_wrist_y', 'right_elbow_y', 'right_heel_x', 'left_heel_y', 'right_hip_x', 'left_index_z', 'right_wrist_x', 'right_pinky_x', 'left_thumb_y', 'right_thumb_z', 'right_ankle_y', 'left_index_x']\n",
    "\n",
    "X_train_feature_eng=X_train.drop(columns=columns_to_drop)\n",
    "X_test_feature_eng=X_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints = features_to_split\n",
    "features = X_train_feature_eng.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feature_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rcf_feature_eng_model.pkl', 'rb') as f:\n",
    "    random_tree_model = pickle.load(f)\n",
    "\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#     svc_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(random_tree_model.predict, X_train_feature_eng)\n",
    "shap_values = explainer(X_test_feature_eng[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[19], max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dice = dice_ml.Data(dataframe=pd.concat([X_train_feature_eng, pd.Series(y_train, name=\"label\")], axis=1),\n",
    "                         continuous_features=features, outcome_name=\"label\")\n",
    "\n",
    "model_dice = dice_ml.Model(model=random_tree_model, backend=\"sklearn\")\n",
    "exp = dice_ml.Dice(data_dice, model_dice, method=\"random\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = X_test_feature_eng.iloc[[0]]  # Note the double brackets to keep it as DataFrame\n",
    "\n",
    "cf = exp.generate_counterfactuals(query_instance, total_CFs=1, desired_class=3)\n",
    "cf.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feature_eng.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = query_instance\n",
    "counterfactual = cf.cf_examples_list[0].final_cfs_df.iloc[0]\n",
    "\n",
    "diffs = (counterfactual - original).abs()\n",
    "important_joints = set()\n",
    "for joint in joints:\n",
    "    if any(diffs[f'{joint}_{axis}'] > 0.01 for axis in ['x', 'y', 'z']):\n",
    "        important_joints.add(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_skeleton(joint_coords, highlighted_joints=set()):\n",
    "    connections = [\n",
    "        ('shoulder', 'elbow'), ('elbow', 'wrist'),\n",
    "        ('hip', 'knee'), ('shoulder', 'hip')\n",
    "    ]\n",
    "    for j1, j2 in connections:\n",
    "        x = [joint_coords[f'{j1}_x'], joint_coords[f'{j2}_x']]\n",
    "        y = [joint_coords[f'{j1}_y'], joint_coords[f'{j2}_y']]\n",
    "        plt.plot(x, y, 'k-', linewidth=2)\n",
    "\n",
    "    for joint in joints:\n",
    "        x = joint_coords[f'{joint}_x']\n",
    "        y = joint_coords[f'{joint}_y']\n",
    "        color = 'red' if joint in highlighted_joints else 'blue'\n",
    "        plt.scatter(x, y, c=color, s=100)\n",
    "        plt.text(x+0.01, y+0.01, joint, fontsize=9)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"Skeleton with Important Joints Highlighted\")\n",
    "    plt.show()\n",
    "\n",
    "plot_skeleton(original.to_dict(), highlighted_joints=important_joints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
